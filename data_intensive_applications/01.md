# 信頼性、スケーラビリティ、メンテナンス性に優れたアプリケーション

演算指向アプリケーション: CPUの処理能力そのものが制約条件になる

データ指向アプリケーション: データの量や複雑さ、変化する速度がが問題になる

今日のアプリケーションのほとんどはデータ指向のアプリケーションである。

データ指向のアプリケーションは一般的に求められる機能を提供する以下の標準的なビルディングブロックから構築される。

- データベース
- キャッシュ
- 検索インデックス
- ストリーム処理
- バッチ処理

これらが当たり前に感じるなら、それは「データシステム」という抽象化が優れているという証拠である。

「データシステム」とは目的を複数のタスクに分割し、それぞれのタスクをそれぞれのツール（上記のビルディングブロック）で効率よく処理できるようにした上で、ツール群をアプリケーションコードで結びつけたものである。

したがって、データシステムを開発する我々はアプリケーション開発者であると同時に設計者でもあるらしい。

データシステムには主要な3つの課題がある。

- 信頼性
    - システムは障害があっても正しく動作し続ける
- スケーラビリティ
    - システムは成長（データ量、トラフィック量の増加・複雑化）に対して無理のない方法で対応可能である
- メンテナンス性
    - 多くの人がシステムに生産的に関われる

これらから、本書の目的は **「信頼性とスケーラビリティを保ちながらメンテナンスしやすいデータシステムを構築する基礎（≠ easy）を学ぶ」** ことである。

## 1.2 信頼性

**なにか問題が発生しても正しく動作し続けること。**

**問題** とは（詳しくは後述）

- ハードウェアの障害
- ソフトウェアの障害
- ヒューマンエラー

**正しく動作する** とは

- アプリケーションがユーザーの期待通りに動作する
- ユーザーの間違いや予想外の動作に耐えられる
- 予想されていたデータ量・負荷のもとで十分なパフォーマンスを発揮する
- 認可されていないアクセス、攻撃を回避できる

### 1.2.1 ハードウェアの障害

#### データセンター（オンプレ）環境

e.g.
- ハードディスクのクラッシュ
- RAMの欠陥
- 電力網の停止
- ケーブルの抜き間違え （`ヒューマンエラーでは…?`）

=> マシンの冗長化で対応可能

#### クラウド環境

`[単一の信頼性] < [エラスティック性（柔軟性）]`

=> 単一のマシンが完全に失われても耐えられるシステムが必要

### 1.2.2 ソフトウェアの障害

ハードウェアの障害はランダム性が強いが、ソフトウェアの障害は一度に多くの影響を出しやすい。

- ソフトウェアのバグ
    - 2012/6/30 のうるう秒におけるLinuxカーネルのバグ
- プロセスの暴走
    - 共有リソース（CPU時間、メモリ、ディスク領域、ネットワーク帯域）を使い切る
- システムが依存するサービスに発生した問題
- カスケード障害
    - 障害が起きたノードに分散されるはずの負荷が他のノードにかかり、障害が連鎖していく

上記の問題は **動作環境の前提が何らかの理由で正しくなくなった** ために引き起こされる。

このような問題を **手っ取り早く解決する方法はない**。

発生を防ぐためには以下の点に注意する。

- システムの前提・システム内のやりとりを注意深く考える
- テストの徹底
- プロセスの分離
- プロセスのクラッシュと再起動の許容 （`詳しくないので意図がわからない`）
- 計測とモニタリング
- システム挙動の分析

`コツコツやっていきましょう… ざっくりとしか書いていませんでした。今後詳細に解説される…はず!!`

### 1.2.3 ヒューマンエラー

`障害とエラーを使い分けるのでは… 単語の兼ね合いか…?`

> 最大限に努力しても、人間には信頼性がないことが知られています。

実際に起きた障害のうち、ハードウェアの障害が占める割合は **10~25%** 程度である。

人間が信頼出来ないことを踏まえた上でヒューマンエラーを低減させるような優れたシステムは以下のアプローチの組み合わせで成り立つ。

- 「正しいことを行いやすく」「間違ったことを行いにくい」管理ユーザーインタフェース
    - ただし、制約を強くしすぎると人間はハックしようとするのでバランスが重要（`難しすぎ…`）
- **完全な機能を持ったサンドボックス環境を用意する**
- 自動化された徹底的なテスト
- カナリーリリース
- 詳細なモニタリング
- 優れた管理方法とトレーニングの実践 （`本書の範囲外`）

## 1.3 スケーラビリティ

性能劣化の主要な原因のひとつは負荷（同時接続数、データ量 etc.）の増大である。

**スケーラビリティは負荷の増大に対してシステムが対応できる能力** のこと。

スケーラビリティは1次元のラベルではない。
ある側面での成長に対してどんな選択肢があるか、どのようにコンピュータリソースを追加すれば負荷の増大に対応できるか?といった視点で考える。

### 1.3.1 負荷の表現

成長に関する議論のためには、現在の負荷を表現（数値化）する必要がある。

**負荷パラメータ** はアーキテクチャによって異なるが、例として以下のようなものが考えられる。

- Webサーバー: `request/sec`
- DB: 読み書き比率
- チャットアプリケーション: 同時接続数
- キャッシュ: ヒット率

ケーススタディとしてツイッターを見ていく

TODO: できればまとめる

`結局 '負荷パラメータ' の定義って…??`

### 1.3.2 パフォーマンスの表現

負荷が増大した際に起こることを調べる方法

- システムのリソースを一定に保ったまま、負荷のパラメータを増やした場合、パフォーマンスにどのような影響が出るか
- 負荷のパラメータを増やした際にパフォーマンスを一定に保つにはリソースをどれほど増やさねばならないか

どのパフォーマンスに注目するか

- バッチ処理システム（Hadoopなど）: スループットに注目
- オンラインシステム（Webアプリケーションなど）: レスポンスタイムに注目

#### レスポンスタイムについて

レスポンスタイムには以下のように外れ値が含まれる

- リクエストに起因
    - 処理するデータが大きいリクエスト
- リクエストに起因しない
    - バックグラウンドプロセスへのコンテキストスイッチ
    - ネットワークのパケットロス
    - TCPの再送
    - ガベージコレクションによる一時停止
    - ページフォルト
    - サーバーラックの振動

したがって算術平均（mean）を採用するのが一般的だが、ユーザーの典型的な待ち時間を知るためには中央値をはじめとした **タイルレイテンシ** に注目したほうが良い。

より外れ値に注目するにはより大きいパーセンタイル値に注目する（95%, 99%）。タイルレイテンシはSLA, SLOにも利用される。

### 1.3.3 負荷への対処のアプローチ

負荷の表現とパフォーマンスについて述べたので次はアプローチに関して議論する。

**負荷のパラメータがある程度増加しても優れたパフォーマンスを保つにはどうすればよいか?** （`'ある程度'とは??`）

=> 負荷の桁が増えるたびにアーキテクチャを見直す必要がある。

**急にスケーリングについて**

- スケールアップ（垂直スケール）
    - マシン単体の性能を上げる
    - 単純
    - 高価
- スケールアウト（水平スケール）
    - マシンの台数を増やす
    - 複雑（ステートフルならなおさら）
    - 比較的安価

**「エラスティック」について**

負荷の増大を検知して、自動的にコンピューティングリソースを追加する。（`水平か垂直かは定義されていない感じ??`）

大規模な環境下で運用されるシステムアーキテクチャは通常はアプリケーションの固有の度合いが高い。しかし、構成は **典型的なビルディングプロック** である。

汎用的で1つのサイズですべてのケースに対応できる（one-size-fits-all）スケーラブルなアーキテクチャは存在しない（魔法のスケーリングソースと呼ばれるらしい）。

**どういった処理が頻繁に行われ、どういった処理がまれなのかを推定し、その負荷パラメータのもとに構築する。**

## 1.4 メンテナンス性

`メンテナンス性 = 運用性 + 単純性 + 進化性`

よく知られていることだが、ソフトウェアのコストは初期の開発コストだけでなく **メンテナンスコスト** も生じる。

e.g.
- バグ修正
- システムが運用し続けられるようにすること
- 障害の調査
- 新しいプラットフォームへの対応
- 新しいユースケースへの対応（修正）
- 技術負債の変換
- 新機能の追加

メンテナンスの苦痛を最小化し、レガシーとなるソフトウェアを生み出すのを避ける設計のために、以下の3つの設計原則に注意する。

1. 運用性: 運用チームが扱いやすくする
2. 単純性: 新しいエンジニアがシステムを理解しやすくする
3. 進化性: 要求の変化に対応しやすくする（拡張性、修正の容易性、プラスティシティとも呼ばれる）

**上記のメンテナンス性を達成する単純な方法はない。**

各原則を詳しく見ていく。

### 1.4.1 運用性: 運用担当者への配慮
> これまで「劣悪な（あるいは完成度の低い）ソフトウェアの制約は、しばしば優れた運用によって回避できるが、運用が悪ければ優れたソフトウェアも信頼を保って動作することはできない」と言われてきました。

`過去形??いまは?`

優れた運用チームの責任（これらがすべてというわけではない）

- システム全体をモニタリングし、その状態が悪くなれば素早くサービスを回復させる
- システムの障害やパフォーマンスの低下といった問題の原因を発見する
- ソフトウェアやプラットフォームを最新の状態に保つ。（セキュリティパッチも含む）
- 様々なシステムの相互作用に注目し、問題がありそうな変更があればそれがダメージを生じさせる前に回避する
- 将来の問題を予想し、それらを発生前に解決する（e.g. キャパプラ）
- デプロイメント、設定管理などのための優れたプラクティスやツールを確立する
- プラットフォーム間でのアプリケーションの移動など、複雑なメンテナンスタスクを実行する
- 設定変更の際にシステムのセキュリティメンテナンスを行う
- 運用で予想外のことが怒らないようにプロセスを定義し、プロダクション環境の安定を保つ
- 個人の出入りがあっても、システムに関する組織の知識が保たれるようにする

提携のタスクを容易にするために

TODO: 埋める（21下のリストを参照）

### 1.4.2 単純さ: 複雑さの管理

複雑さにハマったコードを **巨大な泥の玉（Big ball of mud）** と呼ぶらしい。

複雑さの症状は例えば以下のようなものが挙げられる。

- 状態空間の爆発
- モジュール間の密結合
- 依存関係のもつれ
- 一貫性のない命名規則、用語
- パフォーマンスの問題を解決するためのハック
- 特別なケースへの対応

それらによって次のようなことが引き起こされる。

- 予算・スケジュールの超過
- 変更時のバグの混入リスク上昇
- （理解しにくいがゆえに）隠れた前提、意図されていなかった結果、予想外のやり取りが見逃されやすくなっていく

**システムを単純にしよう!! （≠ 機能を減らす）**

単純にする => **偶発的な複雑さ** を取り除く。

偶発的な不雑さとは「ソフトウェアが解決しようとしている（ユーザーから見た）問題がもともとは持っておらず、実装からのみ生じた複雑さ」のこと。

偶発的な複雑さを取り除くためには優れた抽象化を行うことが効果的だが、これはとても難しい問題で、解決されていない。

### 1.4.3 進化性: 変更への配慮

**「システムに対する要求が未来永劫変わらないことなどありえない」**

組織プロセスの観点では **アジャイル** が変化に適応するためのフレームワークを提供してくれる（TDD、リファクタリングなど）。しかし、アジャイルの多くは小さなローカルスケールに焦点を当てている。
そこで本書は複数のアプリケーション・システムから構成される大規模なデータシステムのアジリティを高める方法を考える。

## まとめ

- 信頼性
    - 問題が発生してもシステムは正しく動作すること（ハードウェア・ソフトウェア・人間 に起因する）
- スケーラビリティ
    - 負荷が増大したとしても、優れたパフォーマンスを保てるための戦略を備えていること
- メンテナンス性
    - 優れた抽象化によって複雑性が減り、修正が容易である
    - システムの健全性が可視化されており、効率的な管理方法がある

**残念ながら、上記の3つを高める簡単な方法は存在しない。しかし、繰り返し現れるパターンが存在するのでそれらを学んでいく。

